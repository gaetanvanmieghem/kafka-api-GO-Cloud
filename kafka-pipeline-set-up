package main

// import
import (
	"context"
	"fmt"
	"os"
	"os/signal"
	"strings"
	"syscall"

	"github.com/confluentinc/confluent-kafka-go/kafka"
)

func main() {
	// Configure Kafka consumer
	consumer, err := kafka.NewConsumer(&kafka.ConfigMap{
		"bootstrap.servers":  "localhost:9092", // needs to be the Kafka broker's address
		"group.id":           "my-group",
		"auto.offset.reset":  "earliest",
		"enable.auto.commit": "false",
	})
	if err != nil {
		fmt.Printf("Failed to create consumer: %s\n", err)
		os.Exit(1)
	}
	defer consumer.Close()

	// Subscribe to input topic
	err = consumer.SubscribeTopics([]string{"input-topic"}, nil) // replace input-topic with correct input topic
	if err != nil {
		fmt.Printf("Failed to subscribe to topic: %s\n", err)
		os.Exit(1)
	}

	// Configure Kafka producer
	producer, err := kafka.NewProducer(&kafka.ConfigMap{"bootstrap.servers": "localhost:9092"}) // needs to be the Kafka broker's address
	if err != nil {
		fmt.Printf("Failed to create producer: %s\n", err)
		os.Exit(1)
	}
	defer producer.Close()

	// Trap SIGINT and SIGTERM to gracefully shutdown
	sigchan := make(chan os.Signal, 1)
	signal.Notify(sigchan, syscall.SIGINT, syscall.SIGTERM)

	// Process messages
	run := true
	for run == true {
		select {
		case sig := <-sigchan:
			fmt.Printf("Caught signal %v: terminating\n", sig)
			run = false

		default:
			msg, err := consumer.ReadMessage(-1)
			if err == nil {
				// Process message
				key := strings.ToUpper(string(msg.Key))
				value := strings.ToUpper(string(msg.Value))

				// Produce processed message to output topic
				producer.Produce(&kafka.Message{
					TopicPartition: kafka.TopicPartition{Topic: &[]string{"output-topic"}[0], Partition: kafka.PartitionAny}, // replace output-topic with correct output topic
					Key:            []byte(key),
					Value:          []byte(value),
				}, nil)
			} else {
				fmt.Printf("Consumer error: %v (%v)\n", err, msg)
			}
		}
	}

	// Close consumer and producer
	consumer.Close()
	producer.Flush(15 * 1000)
}
